---
layout: page
title: Shahzad Rasool - Research
---
# Research Funding  
## In Progress  
* Managing Student Stress: Building Application to help reduce stress, National University of Sciences and Technology (NUST), IRP-24-06, **PKR 1,000,000**, 2024-2025 *Principal Investigator*

## Completed  
* Development of a Virtual Reality Training and Testing System for Learning in Complex Domains, Higher Education Commission (HEC), Pakistan, 20-14785/NRPU/R&D/HEC/2021, **PKR 6,282,000**, 2022-2024 *Principal Investigator*  
* Virtual reality simulation for vehicle driving training through restricted outdoor regions, HQ1C PA, Pakistan, **PKR 4,868,600**, 2022-2023 *Principal Investigator*  
* Virtual reality training simulator for critical multi-operator vehicle, Research and Development Establishment, Pakistan, **PKR 50,326,051**, 2022-2024 *Principal Investigator*  
* Simulation of vehicle operator procedures in virtual reality, HQ1C PA, Pakistan, **PKR 2,000,000**, 2022 *Principal Investigator*
* Development of vision-based insect flight tracking environment for flight performance estimation of perching and prey-predator maneuver, Higher Education Commission (HEC), Pakistan, 20-13395/NRPU/RGM/R&D/HEC/2020, **PKR 7,667,442**, 2021-2024 *Co-Principal Investigator*
* Tangible Video Communication, Higher Education Commission (HEC), Pakistan, 1469/SRGP/R&D/HEC/2017, **PKR 361,690**, 2017-2018 *Principal Investigator*

# Research Areas

The current focus of my research is on interdisciplinary applications falling under two areas.

## Immersive Interaction  
### Chemmersive: Interactive visualization of chemical structures  

   <img align="right" width="230" src="../images/chemmersive.png">  

   * Integration of spatial skills and conceptual knowledge is essential for comprehension of chemistry concepts. However, model perception along with the understanding of spatial processes and spatial structures of molecules has been a cause of difficulty for students as conventional teaching methods cannot fully aid student comprehension. We investigate if the spatial learning process of   students can be aided by automatically creating a link between 2D representations of chemical structures and 3D molecular visualization. 

### Multimodal input  
 
   <img align="right" width="220" src="../images/hapticUAV.png">  

   * Flying an unmanned aerial vehicle (UAV) is a challenging task, due to the absence of direct sensory information such as a view of surroundings, sound, vibrations, and motion. It is important to provide these sensory stimulations to an operator for better situational awareness and efficient control. We study the effects of incorporating haptic feedback in UAV flight control. The research is aimed at investigating the hypothesis that while the presence of accurately modeled haptic forces provides better control of a UAV, unrealistic or exaggerated forces may produce better handling of the aircraft. We further investigate the role of haptic feedback in UAV handling varies for different phases of flight. A single force model may not produce better navigational control across all phases of flight.  
   * We study the utility of different physiological measures i.e. heart rate variability (HRV), Galvanic Skin Response (GSR), pupil dilation, brain activity (different brain waves), facial features and different subjective measures to assess operator workload in a single operator-multivehicle command and control simulation. We explore different algorithms of mental workload and fatigue detection using EEG.  

   <img align="right" width="240" src="../images/tangibleVideoFlow.jpg">  

   * We explore ways of using existing video communication tools to achieve a higher sense of immersion through haptic feedback. Different interaction devices are used by the local user to control a remote haptic devices operated by the remote user. Efficient methods of generating haptic forces are explored. They are derived from the image/video content or transmitted asynchronously eliminating the need to modify existing communication tools.  
     <img align="left" width="200" src="../images/tangibleVideoDemo.png">  
     The aim is to minimize the amount of information exchanged and reduce the network transmission delay so that seamless interaction can be achieved. We investigate the tradeoff that exists between the quality of haptic feedback and cost of such a system. Application scenarios can be envisaged where such tangible video communication can be very useful.  
<p></p>  

### Immersive Visualization   
 
   <img align="right" width="220" src="../images/sheep.png">  

   * We attempt to increase the level of immersion to applications not traditionally considered for immersive visualization. Can we train animals through AR? Animals have the cognitive ability just like humans but understanding of animal cognition is limited in comparison. We investigate if we can manipulate animal behavior using Augmented Reality and if yes, then upto what extent. Special head mounted displays are designed, experiments to gain insights into 3D vision and acceptable frame rates of sheep are conducted.  

   <img align="right" width="350" src="../images/NUSTNav.png">  

   * Can we use low-cost head-mounted displays for immersive visualization to aid drivers? In-house algorithms for navigation are developed and implemented into a proof-of-concept application for AR navigation, within NUST H-12 campus, by placing directions directly in the FOV.  
<p></p>  

## Vision and Graphics  
### Grey is the new RGB?  

   <img align="right" width="400" src="../images/GANCompress.png">  

   * GAN-based image colorization techniques are capable of producing highly realistic color in real-time. Subjective assessment of these approaches has demonstrated that humans are unable to differentiate between a true RGB image and a colorized image. In this work, we evaluate the fidelity of such colorization and for the first time analyze the GAN-based image colorization scheme in the context of image compression. Our analysis shows that the palette (set of colors) recommended by the GAN-based framework is very limited even for highly realistic interactive colorization. We propose two novel methods of automatic palette generation that allows for the GAN-based framework to be useful for image compression. We demonstrate that provided true colors at a few pixel locations, GAN-based approach results in good spread of color to other image regions. Subjective analysis on a number of public datasets shows that the current system has low fidelity but performs better than JPEG at low data rate regimes.  

### Few-shot object detection in aerial images  
   * Object detection has attracted a lot of research due to remarkable breakthroughs in the field of deep learning. Yet it remains only a partially solved problem, with state-of-the-art methods achieving barely satisfactory mean accuracy on benchmarks like MS COCO. The domain shift from real-life images to aerial imagery further adds the limitations of scarcity and disparity of data, large size of images, small size of objects apart from the challenges of scene complexity, variations in size and orientations, class imbalance and crowding of objects, to name a few. We investigate methods of object detection that can handle such constraints to detect with high accuracy small objects in large images given few training examples while ensuring high computational efficiency.

# Research Students
## Current Students
  1. **Amna Khan** _PhD CSE_ (2022-Present)
  2. **Naureen Mansoor** _MS CSE_ (2025-Present)

## Previous Students
  1. **Warda Ayaz** (2024-2025)  
     Human-Factor Evaluations for Virtual Reality Interactions Using EEG
  2. **Muhammad Hamza Saleem** (2024 - 2025)  
     Comparative Evaluation of Cybersickness Mitigation Techniques using a Unified Scoring System in VR
  3. **Hifsa Shahid** (2024-2025)  
     Emotional Responses to Design Elements in Virtual Environments
  4. **Mian Muhammad Fatik Owais** (2022-2024)  
     Electric Muscle Stimulation for Haptic Feedback in Virtual Reality Environment
  5. **Maira Sohail** (2022-2024)  
     Immersive Virtual Reality based Gamified Stereochemistry Learning
  6. **Fiza Azam** (2023-2024)  
     Collaborative Task Performance via Real-Time Interaction with Intelligent Virtual Agents
  7. **Raheela Raza** (2023-2024)  
     Exploring provision of hints in a puzzle game and their influence on engagement and performance
  8. **Urwa Ejaz** (2023-2024)  
     Investigating the Neural Corelates of Stiffness Perception using Force and Pseudo-Haptic Feedback
  9. **Muhammad Adil Talay** (2020-2024)  
  10. **Sofia Mohammad** (2023-2024)  
     An exploration of strategies for effective placement of advertisements in the Metaverse
  11. **Amna Naeem** (2022-2023)  
     Reinforcement Learning Based Agent Training for User Privacy in Metaverse
  12. **Maria Maqbool** (2021-2023)  
     Empowering eco-friendly habits - Designing interactive virtual environments for attitude and behaviour change towards energy conservation
  13. **Kiran Firdaus** (2022-2023)  
     Human stress classification using EEG in response to stand-up comediansâ€™ clips
  14. **Irsa Abbasi** (2020-2023)  
     Developing a virtual reality approach towards a better understanding of different types of enzymes
  15. **Ahmad Javaid** (2021-2022)  
     Analysis of vestibulo-ocular effects on motion sickness in flight simulation
  16. **Syeda Yumna Nasir** (2020-2022)  
     Pseudo-haptic feedback through mid-air action for learning of chemical bond strengths
  17. **Hafsa Tahir** _MS CSE_ (2020-2022)  
     Force feedback for collision avoidance in UAV teleoperation through virtual corridors
  18. **Amna Khan** (2021-2021)  
     Game-induced emotion analysis using electroencephalography
  19. **Neelam Shoaib** (2020-2021)  
     Virtual reality based procedural memorization of general aviation light aircraft
  20. **Attia Nafees ul Haq** (2020-2021)  
     Pure mental state detection using EEG
  21. **Muhammad Ali Bilal** (2018-2021)  
     Cognitive workload analysis in visual and auditory task using EEG signals  
  22. **Umar Shahid** (2019-2020)  
      EEG based mental workload assessment using machine learning  
  23. **Muhammad Adil Talay** (2018-2020)  
      Few-shot metric learning for remote sensing image scene classification  
  24. **Zain ul Abideen** (2018-2020)  
      Development of a cost effective training system for small arms shooting training  
  25. **Hassam Ahmed Malik** (2018-2020)  
      Effect of haptic feedback on pilot/operator performance during flight simulation  
  26. **Amal Fatemah** (2018-2019)  
      Design of an integrated pipeline for the visualization of 3D molecular models to study the effects on spatial learning ability  
  27. **Hasnain Rashid** (2017-2019)  
      Automatic cell detection and counting of microscopic images using machine learning  
  28. **Aroosh Fatima** (2017-2018 )  
      Using deep learning for image and video vompression  
  29. **Syed Rameez Rehman** (2016-2018)  
      A framework for cardboard based augmented reality  
  30. **Samin Kainat** (2016-2017)  
      Man made world image matching over wide baselines
